---
title: "SAS THESIS"
author: Sara Garza Gonzalez
output: html_document
date: "2025-04-01"
---

```{r, load packages, include=FALSE}
library(tinytex)
library(readr)
library(readxl)
library(data.table)
library(tidyr)
library(dplyr)
library(ggplot2)
library(lme4)
library(ggpubr)
library(psych)
library(rcompanion)
library(coin)
library(ggplotgui)
library(table1)
library(supernova)
library(pROC)
library(broom)
library(glmnet)
library(rpart)
library(rpart.plot)
library(ggpattern)
library(lmerTest)

```

```{r, truncating speaker time series}

#set wd for speakers
setwd("~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/speaker_brain/")

SS02_A <- read.csv("SS02_A.csv", header = FALSE)
SS02_A <-SS02_A[-c(1:12), ]

SS11_B <- read.csv("SS11_B.csv", header = FALSE)
SS11_B <- SS11_B[-c(1:4), ]

SS12_C <- read.csv("SS12_C.csv", header = FALSE)
SS12_C <- SS12_C[-c(1:31), ]

SS15_D  <- read.csv("SS15_D.csv", header = FALSE)
SS15_D <- SS15_D[-c(1:157), ] #SL056_D only has 605 rows, so adjusting to this one

SS18_E <- read.csv("SS18_E.csv", header = FALSE)
SS18_E <- SS18_E[-c(1:84), ]

SS19_F <- read.csv("SS19_F.csv", header = FALSE)

SS23_G <- read.csv("SS23_G.csv", header = FALSE)
SS23_G <- SS23_G[-c(1:8), ] #SL036_G only has 918 rows, so adjusting to this one

SS24_H <- read.csv("SS24_H.csv", header = FALSE)
SS24_H <- SS24_H[-c(1:57), ] #SL056_H only has 1260 rows, so adjusting to this one

SS30_I <- read.csv("SS30_I.csv", header = FALSE)
SS30_I <- SS30_I[-c(1:23), ]

SS31_J <- read.csv("SS31_J.csv", header = FALSE)
SS31_J <- SS31_J[-c(1:4), ]

SS33_K <- read.csv("SS33_K.csv", header = FALSE)
SS33_K <- SS33_K[-c(1:65), ]

SS34_L <- read.csv("SS34_L.csv", header = FALSE)

SS41_M <- read.csv("SS41_M.csv", header = FALSE)
SS41_M <- SS41_M[-c(1:8), ]

SS42_N <- read.csv("SS42_N.csv", header = FALSE)
SS42_N <- SS42_N[-c(1:12), ]

```

```{r, make all column names the same for all speaker data frames}

set_colnames <- function(df) {
  colnames(df) <- paste("ch", 1:ncol(df), sep="")
  return(df)  # Return the modified data frame
}

# Apply the function and update each data frame
SS02_A <- set_colnames(SS02_A)
SS11_B <- set_colnames(SS11_B)
SS12_C <- set_colnames(SS12_C)
SS15_D <- set_colnames(SS15_D)
SS18_E <- set_colnames(SS18_E)
SS19_F <- set_colnames(SS19_F)
SS23_G <- set_colnames(SS23_G)
SS24_H <- set_colnames(SS24_H)
SS30_I <- set_colnames(SS30_I)
SS31_J <- set_colnames(SS31_J)
SS33_K <- set_colnames(SS33_K)
SS34_L <- set_colnames(SS34_L)
SS41_M <- set_colnames(SS41_M)
SS42_N <- set_colnames(SS42_N)

```

```{r, make all column names the same for all listener data frames}

# List all CSV files explicitly (case-insensitive match)
file_list <- list.files(path = "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/", pattern = "(?i)\\.csv$", full.names = TRUE)

# Print the list of found CSV files (for debugging)
print(file_list)

# Function to read CSV files and change column names
ChangeNamesAndRead <- function(file) {
  df <- read_csv(file, show_col_types = FALSE)
  
  # Change column names
  colnames(df) <- paste0("ch", 1:ncol(df))
  
  return(df)
}

# Loop through each file and assign the resulting data frame to the global environment
for (i in seq_along(file_list)) {
  file_name <- file_list[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_name <- tools::file_path_sans_ext(basename(file_name))
  
  # Read and change column names
  df <- ChangeNamesAndRead(file_name)
  
  # Assign the dataframe to the global environment
  assign(df_name, df, envir = .GlobalEnv)
}

```

```{r, trimming all listeners A data frames to match Speaker A}

# Set the directory containing your data files
data_dirA <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly (case-insensitive match)
file_listA <- list.files(path = data_dirA, pattern = "(?i)A.*\\.csv$", full.names = TRUE)

#Get the number of rows in the "Speaker A" dataframe
speaker_A_row_count <- nrow(SS02_A)

# Now loop through each listener file and trim to match the row count of "Speaker A"
for (i in seq_along(file_listA)) {
  file_nameA <- file_listA[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameA <- tools::file_path_sans_ext(basename(file_nameA))
  
  # Read the listener data
  listener_dataA <- ChangeNamesAndRead(file_nameA)
  
  # Trim listener data to match the row count of Speaker A
  if (nrow(listener_dataA) >= speaker_A_row_count) {
    trimmed_listener_dataA <- listener_dataA[1:speaker_A_row_count, ]
  } else {
    warning(paste("Listener data", df_name, "has fewer rows than Speaker A. No trimming applied."))
    trimmed_listener_dataA <- listener_dataA
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameA, trimmed_listener_dataA, envir = .GlobalEnv)
}

```

```{r, trimming all listeners B data frames to match Speaker B}

# Set the directory containing your data files
data_dirB <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly that have "B" in their name (case-insensitive match)
file_listB <- list.files(path = data_dirB, pattern = "(?i)B.*\\.csv$", full.names = TRUE)

# Print the list of found files (for debugging)
print(file_listB)

# Get the number of rows in the "Speaker B" dataframe
speaker_B_row_count <- nrow(SS11_B)

# Now loop through each listener file and trim to match the row count of "Speaker B"
for (i in seq_along(file_listB)) {
  file_nameB <- file_listB[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameB <- tools::file_path_sans_ext(basename(file_nameB))
  
  # Read the listener data
  listener_dataB <- ChangeNamesAndRead(file_nameB)
  
  # Trim listener data to match the row count of Speaker B
  if (nrow(listener_dataB) >= speaker_B_row_count) {
    trimmed_listener_dataB <- listener_dataB[1:speaker_B_row_count, ]
  } else {
    warning(paste("Listener data", df_nameB, "has fewer rows than Speaker B. No trimming applied."))
    trimmed_listener_dataB <- listener_dataB
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameB, trimmed_listener_dataB, envir = .GlobalEnv)
}

```

```{r, trimming all listeners C data frames to match Speaker C}

# Set the directory containing your data files
data_dirC <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly (case-insensitive match)
file_listC <- list.files(path = data_dirC, pattern = "(?i)C.*\\.csv$", full.names = TRUE)

#Get the number of rows in the "Speaker C" dataframe
speaker_C_row_count <- nrow(SS12_C)

# Now loop through each listener file and trim to match the row count of "Speaker C"
for (i in seq_along(file_listC)) {
  file_nameC <- file_listC[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameC <- tools::file_path_sans_ext(basename(file_nameC))
  
  # Read the listener data
  listener_dataC <- ChangeNamesAndRead(file_nameC)
  
  # Trim listener data to match the row count of Speaker C
  if (nrow(listener_dataC) >= speaker_C_row_count) {
    trimmed_listener_dataC <- listener_dataC[1:speaker_C_row_count, ]
  } else {
    warning(paste("Listener data", df_name, "has fewer rows than Speaker C. No trimming applied."))
    trimmed_listener_dataC <- listener_dataC
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameC, trimmed_listener_dataC, envir = .GlobalEnv)
}

```

```{r, trimming all listeners D data frames to match Speaker D}

# Set the directory containing your data files
data_dirD <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly (case-insensitive match)
file_listD <- list.files(path = data_dirD, pattern = "(?i)D.*\\.csv$", full.names = TRUE)

#Get the number of rows in the "Speaker D" dataframe
speaker_D_row_count <- nrow(SS15_D)

# Now loop through each listener file and trim to match the row count of "Speaker D"
for (i in seq_along(file_listD)) {
  file_nameD <- file_listD[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameD <- tools::file_path_sans_ext(basename(file_nameD))
  
  # Read the listener data
  listener_dataD <- ChangeNamesAndRead(file_nameD)
  
  # Trim listener data to match the row count of Speaker D
  if (nrow(listener_dataD) >= speaker_D_row_count) {
    trimmed_listener_dataD <- listener_dataD[1:speaker_D_row_count, ]
  } else {
    warning(paste("Listener data", df_name, "has fewer rows than Speaker D. No trimming applied."))
    trimmed_listener_dataD <- listener_dataD
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameD, trimmed_listener_dataD, envir = .GlobalEnv)
}

```

```{r, trimming all listeners E data frames to match Speaker E}

# Set the directory containing your data files
data_dirE <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly (case-insensitive match)
file_listE <- list.files(path = data_dirE, pattern = "(?i)E.*\\.csv$", full.names = TRUE)

#Get the number of rows in the "Speaker E" dataframe
speaker_E_row_count <- nrow(SS18_E)

# Now loop through each listener file and trim to match the row count of "Speaker E"
for (i in seq_along(file_listE)) {
  file_nameE <- file_listE[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameE <- tools::file_path_sans_ext(basename(file_nameE))
  
  # Read the listener data
  listener_dataE <- ChangeNamesAndRead(file_nameE)
  
  # Trim listener data to match the row count of Speaker E
  if (nrow(listener_dataE) >= speaker_E_row_count) {
    trimmed_listener_dataE <- listener_dataE[1:speaker_E_row_count, ]
  } else {
    warning(paste("Listener data", df_name, "has fewer rows than Speaker E. No trimming applied."))
    trimmed_listener_dataE <- listener_dataE
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameE, trimmed_listener_dataE, envir = .GlobalEnv)
}

```

```{r, trimming all listeners F data frames to match Speaker F}

# Set the directory containing your data files
data_dirF <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly (case-insensitive match)
file_listF <- list.files(path = data_dirF, pattern = "(?i)F.*\\.csv$", full.names = TRUE)

#Get the number of rows in the "Speaker F" dataframe
speaker_F_row_count <- nrow(SS19_F)

# Now loop through each listener file and trim to match the row count of "Speaker F"
for (i in seq_along(file_listF)) {
  file_nameF <- file_listF[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameF <- tools::file_path_sans_ext(basename(file_nameF))
  
  # Read the listener data
  listener_dataF <- ChangeNamesAndRead(file_nameF)
  
  # Trim listener data to match the row count of Speaker D
  if (nrow(listener_dataF) >= speaker_F_row_count) {
    trimmed_listener_dataF <- listener_dataF[1:speaker_F_row_count, ]
  } else {
    warning(paste("Listener data", df_name, "has fewer rows than Speaker F. No trimming applied."))
    trimmed_listener_dataF <- listener_dataF
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameF, trimmed_listener_dataF, envir = .GlobalEnv)
}

```

```{r, trimming all listeners G data frames to match Speaker G}

# Set the directory containing your data files
data_dirG <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List all CSV files explicitly (case-insensitive match)
file_listG <- list.files(path = data_dirG, pattern = "(?i)G.*\\.csv$", full.names = TRUE)

#Get the number of rows in the "Speaker G" dataframe
speaker_G_row_count <- nrow(SS23_G)

# Now loop through each listener file and trim to match the row count of "Speaker G"
for (i in seq_along(file_listG)) {
  file_nameG <- file_listG[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameG <- tools::file_path_sans_ext(basename(file_nameG))
  
  # Read the listener data
  listener_dataG <- ChangeNamesAndRead(file_nameG)
  
  # Trim listener data to match the row count of Speaker G
  if (nrow(listener_dataG) >= speaker_G_row_count) {
    trimmed_listener_dataG <- listener_dataG[1:speaker_G_row_count, ]
  } else {
    warning(paste("Listener data", df_name, "has fewer rows than Speaker G. No trimming applied."))
    trimmed_listener_dataG <- listener_dataG
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameG, trimmed_listener_dataG, envir = .GlobalEnv)
}

```

```{r, trimming all listeners H data frames to match Speaker H}

# Set the directory containing your data files
data_dirH <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener H 
file_listH <- list.files(path = data_dirH, pattern = "(?i)SL[0-9]{3}_H\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker H" dataframe
speaker_H_row_count <- nrow(SS24_H)

# Now loop through each listener file and trim to match the row count of "Speaker H"
for (i in seq_along(file_listH)) {
  file_nameH <- file_listH[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameH <- tools::file_path_sans_ext(basename(file_nameH))
  
  # Read the listener data
  listener_dataH <- ChangeNamesAndRead(file_nameH)
  
  # Trim listener data to match the row count of Speaker H
  if (nrow(listener_dataH) >= speaker_H_row_count) {
    trimmed_listener_dataH <- listener_dataH[1:speaker_H_row_count, ]
  } else {
    warning(paste("Listener data", df_nameH, "has fewer rows than Speaker H. No trimming applied."))
    trimmed_listener_dataH <- listener_dataH
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameH, trimmed_listener_dataH, envir = .GlobalEnv)
}

```

```{r, trimming all listeners I data frames to match Speaker I}

# Set the directory containing your data files
data_dirI <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener I 
file_listI <- list.files(path = data_dirI, pattern = "(?i)SL[0-9]{3}_I\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker I" dataframe
speaker_I_row_count <- nrow(SS30_I)

# Now loop through each listener file and trim to match the row count of "Speaker I"
for (i in seq_along(file_listI)) {
  file_nameI <- file_listI[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameI <- tools::file_path_sans_ext(basename(file_nameI))
  
  # Read the listener data
  listener_dataI <- ChangeNamesAndRead(file_nameI)
  
  # Trim listener data to match the row count of Speaker I
  if (nrow(listener_dataI) >= speaker_I_row_count) {
    trimmed_listener_dataI <- listener_dataI[1:speaker_I_row_count, ]
  } else {
    warning(paste("Listener data", df_nameI, "has fewer rows than Speaker I. No trimming applied."))
    trimmed_listener_dataI <- listener_dataI
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameI, trimmed_listener_dataI, envir = .GlobalEnv)
}

```

```{r, trimming all listeners J data frames to match Speaker J}

# Set the directory containing your data files
data_dirJ <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener J 
file_listJ <- list.files(path = data_dirJ, pattern = "(?i)SL[0-9]{3}_J\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker J" dataframe
speaker_J_row_count <- nrow(SS31_J)

# Now loop through each listener file and trim to match the row count of "Speaker J"
for (i in seq_along(file_listJ)) {
  file_nameJ <- file_listJ[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameJ <- tools::file_path_sans_ext(basename(file_nameJ))
  
  # Read the listener data
  listener_dataJ <- ChangeNamesAndRead(file_nameJ)
  
  # Trim listener data to match the row count of Speaker J
  if (nrow(listener_dataJ) >= speaker_J_row_count) {
    trimmed_listener_dataJ <- listener_dataJ[1:speaker_J_row_count, ]
  } else {
    warning(paste("Listener data", df_nameJ, "has fewer rows than Speaker J. No trimming applied."))
    trimmed_listener_dataJ <- listener_dataJ
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameJ, trimmed_listener_dataJ, envir = .GlobalEnv)
}

```

```{r, trimming all listeners K data frames to match Speaker K}

# Set the directory containing your data files
data_dirK <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener K 
file_listK <- list.files(path = data_dirK, pattern = "(?i)SL[0-9]{3}_K\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker K" dataframe
speaker_K_row_count <- nrow(SS33_K)

# Now loop through each listener file and trim to match the row count of "Speaker K"
for (i in seq_along(file_listK)) {
  file_nameK <- file_listK[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameK <- tools::file_path_sans_ext(basename(file_nameK))
  
  # Read the listener data
  listener_dataK <- ChangeNamesAndRead(file_nameK)
  
  # Trim listener data to match the row count of Speaker K
  if (nrow(listener_dataK) >= speaker_K_row_count) {
    trimmed_listener_dataK <- listener_dataK[1:speaker_K_row_count, ]
  } else {
    warning(paste("Listener data", df_nameK, "has fewer rows than Speaker K. No trimming applied."))
    trimmed_listener_dataK <- listener_dataK
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameK, trimmed_listener_dataK, envir = .GlobalEnv)
}

```

```{r, trimming all listeners L data frames to match Speaker L}

# Set the directory containing your data files
data_dirL <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener L 
file_listL <- list.files(path = data_dirL, pattern = "(?i)SL[0-9]{3}_L\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker L" dataframe
speaker_L_row_count <- nrow(SS34_L)

# Now loop through each listener file and trim to match the row count of "Speaker L"
for (i in seq_along(file_listL)) {
  file_nameL <- file_listL[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameL <- tools::file_path_sans_ext(basename(file_nameL))
  
  # Read the listener data
  listener_dataL <- ChangeNamesAndRead(file_nameL)
  
  # Trim listener data to match the row count of Speaker L
  if (nrow(listener_dataL) >= speaker_L_row_count) {
    trimmed_listener_dataL <- listener_dataL[1:speaker_L_row_count, ]
  } else {
    warning(paste("Listener data", df_nameL, "has fewer rows than Speaker L. No trimming applied."))
    trimmed_listener_dataL <- listener_dataL
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameL, trimmed_listener_dataL, envir = .GlobalEnv)
}

```

```{r, trimming all listeners M data frames to match Speaker M}

# Set the directory containing your data files
data_dirM <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener M 
file_listM <- list.files(path = data_dirM, pattern = "(?i)SL[0-9]{3}_M\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker M" dataframe
speaker_M_row_count <- nrow(SS41_M)

# Now loop through each listener file and trim to match the row count of "Speaker M"
for (i in seq_along(file_listM)) {
  file_nameM <- file_listM[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameM <- tools::file_path_sans_ext(basename(file_nameM))
  
  # Read the listener data
  listener_dataM <- ChangeNamesAndRead(file_nameM)
  
  # Trim listener data to match the row count of Speaker M
  if (nrow(listener_dataM) >= speaker_M_row_count) {
    trimmed_listener_dataM <- listener_dataM[1:speaker_M_row_count, ]
  } else {
    warning(paste("Listener data", df_nameM, "has fewer rows than Speaker M. No trimming applied."))
    trimmed_listener_dataM <- listener_dataM
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameM, trimmed_listener_dataM, envir = .GlobalEnv)
}

```

```{r, trimming all listeners N data frames to match Speaker N}

# Set the directory containing your data files
data_dirN <- "~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_brain/New Folder With Items/"

# List only files with the exact format for listener N 
file_listN <- list.files(path = data_dirN, pattern = "(?i)SL[0-9]{3}_N\\.csv$", full.names = TRUE)

# Get the number of rows in the "Speaker N" dataframe
speaker_N_row_count <- nrow(SS42_N)

# Now loop through each listener file and trim to match the row count of "Speaker N"
for (i in seq_along(file_listN)) {
  file_nameN <- file_listN[i]
  
  # Get the base file name (without path and extension) to use as the data frame name
  df_nameN <- tools::file_path_sans_ext(basename(file_nameN))
  
  # Read the listener data
  listener_dataN <- ChangeNamesAndRead(file_nameN)
  
  # Trim listener data to match the row count of Speaker N
  if (nrow(listener_dataN) >= speaker_N_row_count) {
    trimmed_listener_dataN <- listener_dataN[1:speaker_N_row_count, ]
  } else {
    warning(paste("Listener data", df_nameN, "has fewer rows than Speaker N. No trimming applied."))
    trimmed_listener_dataN <- listener_dataN
  }
  
  # Assign the trimmed listener data to the global environment
  assign(df_nameN, trimmed_listener_dataN, envir = .GlobalEnv)
}

```

```{r, creating new empty data frame}
dyads_df <- setNames(data.frame(matrix(ncol = 104, nrow = length(file_list))), 
                     c("speaker_id", "listener_id", "video_id", "shared_exp", 
                       paste0("ch", 1:100)))
```

```{r, correlations matrixes}

# Function to calculate correlations and update the dataframe
calculate_correlations <- function(speaker_data, listener_data, speaker_id, listener_id, video_id, dyad_row) {
  # Create a list to store the correlations for each channel pair
  channel_correlations <- vector("list", length = 100)
  
  # Loop through channels 1 to 100
  for (i in 1:100) {
    # Create channel names ('ch1', 'ch2', ..., 'ch100')
    channel_name <- paste0("ch", i)
    
    # Check if the channel exists in the data
    if (channel_name %in% names(speaker_data) && channel_name %in% names(listener_data)) {
      # Subset the data for the current channel for both speaker and listener
      speaker_channel_data <- speaker_data[[channel_name]]  # Data for speaker
      listener_channel_data <- listener_data[[channel_name]] # Data for listener
      
      # Remove NAs from both speaker and listener data before calculating the correlation
      valid_indices <- complete.cases(speaker_channel_data, listener_channel_data)
      speaker_channel_data <- speaker_channel_data[valid_indices]
      listener_channel_data <- listener_channel_data[valid_indices]
      
      # Check if both speaker and listener have valid data left after removing NAs
      if (length(speaker_channel_data) > 0 && length(listener_channel_data) > 0) {
        # Calculate the correlation and store it in the list, ignoring NAs
        correlation_value <- cor(speaker_channel_data, listener_channel_data)
        channel_correlations[[i]] <- correlation_value
      } else {
        # If no valid data for correlation, assign NA to that channel
        channel_correlations[[i]] <- NA
      }
    } else {
      # If the channel doesn't exist in either speaker or listener data, assign NA
      channel_correlations[[i]] <- NA
    }
  }
  
  # Convert the list to a vector for easier insertion into the dataframe
  correlations <- unlist(channel_correlations)
  
  # Check for NAs in correlations before assigning to dyads_df
  if (all(is.na(correlations))) {
    message(paste("Warning: All correlations are NA for dyad", speaker_id, listener_id, "in video", video_id))
  }

  # Insert the identifiers and correlation values into the dyad_row
  dyads_df[dyad_row, 1:4] <- c(speaker_id, listener_id, video_id, NA)  # Ensure shared experience is correctly handled
  dyads_df[dyad_row, 5:104] <- correlations  # Insert the correlation values into columns 'ch1' to 'ch100'
  
  # Return the updated dataframe
  return(dyads_df)
}

```

```{r, Speaker A}

# First Dyad
dyads_df <- calculate_correlations(SS02_A, SL034_A, "SS02_A", "SL034_A", "A", 1)

# Second Dyad
dyads_df <- calculate_correlations(SS02_A, SL040_A, "SS02_A", "SL040_A", "A", 2)

# Third Dyad
dyads_df <- calculate_correlations(SS02_A, SL041_A, "SS02_A", "SL041_A", "A", 3)

# Fourth Dyad
dyads_df <- calculate_correlations(SS02_A, SL051_A, "SS02_A", "SL051_A", "A", 4)

# Fifth Dyad
dyads_df <- calculate_correlations(SS02_A, SL053_A, "SS02_A", "SL053_A", "A", 5)

# Sixth Dyad
dyads_df <- calculate_correlations(SS02_A, SL058_A, "SS02_A", "SL058_A", "A", 6)

# Seventh Dyad
dyads_df <- calculate_correlations(SS02_A, SL068_A, "SS02_A", "SL068_A", "A", 7)

# Eighth Dyad
dyads_df <- calculate_correlations(SS02_A, SL070_A, "SS02_A", "SL070_A", "A", 8)

# Ninth Dyad
dyads_df <- calculate_correlations(SS02_A, SL072_A, "SS02_A", "SL072_A", "A", 9)

# Tenth Dyad
dyads_df <- calculate_correlations(SS02_A, SL081_A, "SS02_A", "SL081_A", "A", 10)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS02_A, SL085_A, "SS02_A", "SL085_A", "A", 11)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS02_A, SL088_A, "SS02_A", "SL088_A", "A", 12)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS02_A, SL091_A, "SS02_A", "SL091_A", "A", 13)

```

```{r, Speaker B}

# First Dyad
dyads_df <- calculate_correlations(SS11_B, SL033_B, "SS11_B", "SL033_B", "B", 14)

# Second Dyad
dyads_df <- calculate_correlations(SS11_B, SL044_B, "SS11_B", "SL044_B", "B", 15)

# Third Dyad
dyads_df <- calculate_correlations(SS11_B, SL045_B, "SS11_B", "SL045_B", "B", 16)

# Fourth Dyad
dyads_df <- calculate_correlations(SS11_B, SL065_B, "SS11_B", "SL065_B", "B", 17)

# Fifth Dyad
dyads_df <- calculate_correlations(SS11_B, SL067_B, "SS11_B", "SL067_B", "B", 18)

# Sixth Dyad
dyads_df <- calculate_correlations(SS11_B, SL069_B, "SS11_B", "SL069_B", "B", 19)

# Seventh Dyad
dyads_df <- calculate_correlations(SS11_B, SL070_B, "SS11_B", "SL070_B", "B", 20)

# Eighth Dyad
dyads_df <- calculate_correlations(SS11_B, SL074_B, "SS11_B", "SL074_B", "B", 21)

# Ninth Dyad
dyads_df <- calculate_correlations(SS11_B, SL078_B, "SS11_B", "SL078_B", "B", 22)

# Tenth Dyad
dyads_df <- calculate_correlations(SS11_B, SL083_B, "SS11_B", "SL083_B", "B", 23)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS11_B, SL084_B, "SS11_B", "SL084_B", "B", 24)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS11_B, SL085_B, "SS11_B", "SL085_B", "B", 25)

```

```{r, Speaker C}

# First Dyad
dyads_df <- calculate_correlations(SS12_C, SL033_C, "SS12_C", "SL033_C", "C", 26)

# Second Dyad
dyads_df <- calculate_correlations(SS12_C, SL036_C, "SS12_C", "SL036_C", "C", 27)

# Third Dyad
dyads_df <- calculate_correlations(SS12_C, SL051_C, "SS12_C", "SL051_C", "C", 28)

# Fourth Dyad
dyads_df <- calculate_correlations(SS12_C, SL052_C, "SS12_C", "SL052_C", "C", 29)

# Fifth Dyad
dyads_df <- calculate_correlations(SS12_C, SL054_C, "SS12_C", "SL054_C", "C", 30)

# Sixth Dyad
dyads_df <- calculate_correlations(SS12_C, SL061_C, "SS12_C", "SL061_C", "C", 31)

# Seventh Dyad
dyads_df <- calculate_correlations(SS12_C, SL063_C, "SS12_C", "SL063_C", "C", 32)

# Eighth Dyad
dyads_df <- calculate_correlations(SS12_C, SL071_C, "SS12_C", "SL071_C", "C", 33)

# Ninth Dyad
dyads_df <- calculate_correlations(SS12_C, SL074_C, "SS12_C", "SL074_C", "C", 34)

# Tenth Dyad
dyads_df <- calculate_correlations(SS12_C, SL075_C, "SS12_C", "SL075_C", "C", 35)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS12_C, SL086_C, "SS12_C", "SL086_C", "C", 36)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS12_C, SL092_C, "SS12_C", "SL092_C", "C", 37)

```

```{r, Speaker D}

# First Dyad
dyads_df <- calculate_correlations(SS15_D, SL039_D, "SS15_D", "SL039_D", "D", 38)

# Second Dyad
dyads_df <- calculate_correlations(SS15_D, SL047_D, "SS15_D", "SL047_D", "D", 39)

# Third Dyad
dyads_df <- calculate_correlations(SS15_D, SL050_D, "SS15_D", "SL050_D", "D", 40)

# Fourth Dyad
dyads_df <- calculate_correlations(SS15_D, SL056_D, "SS15_D", "SL056_D", "D", 41)

# Fifth Dyad
dyads_df <- calculate_correlations(SS15_D, SL059_D, "SS15_D", "SL059_D", "D", 42)

# Sixth Dyad
dyads_df <- calculate_correlations(SS15_D, SL064_D, "SS15_D", "SL064_D", "D", 43)

# Seventh Dyad
dyads_df <- calculate_correlations(SS15_D, SL075_D, "SS15_D", "SL075_D", "D", 44)

# Eighth Dyad
dyads_df <- calculate_correlations(SS15_D, SL079_D, "SS15_D", "SL079_D", "D", 45)

# Ninth Dyad
dyads_df <- calculate_correlations(SS15_D, SL081_D, "SS15_D", "SL081_D", "D", 46)

# Tenth Dyad
dyads_df <- calculate_correlations(SS15_D, SL086_D, "SS15_D", "SL086_D", "D", 47)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS15_D, SL088_D, "SS15_D", "SL088_D", "D", 48)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS15_D, SL091_D, "SS15_D", "SL091_D", "D", 49)

```

```{r, Speaker E}

# First Dyad
dyads_df <- calculate_correlations(SS18_E, SL032_E, "SS18_E", "SL032_E", "E", 50)

# Second Dyad
dyads_df <- calculate_correlations(SS18_E, SL034_E, "SS18_E", "SL034_E", "E", 51)

# Third Dyad
dyads_df <- calculate_correlations(SS18_E, SL045_E, "SS18_E", "SL045_E", "E", 52)

# Fourth Dyad
dyads_df <- calculate_correlations(SS18_E, SL051_E, "SS18_E", "SL051_E", "E", 53)

# Fifth Dyad
dyads_df <- calculate_correlations(SS18_E, SL057_E, "SS18_E", "SL057_E", "E", 54)

# Sixth Dyad
dyads_df <- calculate_correlations(SS18_E, SL058_E, "SS18_E", "SL058_E", "E", 55)

# Seventh Dyad
dyads_df <- calculate_correlations(SS18_E, SL063_E, "SS18_E", "SL063_E", "E", 56)

# Eighth Dyad
dyads_df <- calculate_correlations(SS18_E, SL076_E, "SS18_E", "SL076_E", "E", 57)

# Ninth Dyad
dyads_df <- calculate_correlations(SS18_E, SL083_E, "SS18_E", "SL083_E", "E", 58)

# Tenth Dyad
dyads_df <- calculate_correlations(SS18_E, SL084_E, "SS18_E", "SL084_E", "E", 59)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS18_E, SL085_E, "SS18_E", "SL085_E", "E", 60)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS18_E, SL086_E, "SS18_E", "SL086_E", "E", 61)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS18_E, SL088_E, "SS18_E", "SL088_E", "E", 62)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS18_E, SL092_E, "SS18_E", "SL092_E", "E", 63)

```

```{r, Speaker F}

# First Dyad
dyads_df <- calculate_correlations(SS19_F, SL033_F, "SS19_F", "SL033_F", "F", 64)

# Second Dyad
dyads_df <- calculate_correlations(SS19_F, SL037_F, "SS19_F", "SL037_F", "F", 65)

# Third Dyad
dyads_df <- calculate_correlations(SS19_F, SL039_F, "SS19_F", "SL039_F", "F", 66)

# Fourth Dyad
dyads_df <- calculate_correlations(SS19_F, SL040_F, "SS19_F", "SL040_F", "F", 67)

# Fifth Dyad
dyads_df <- calculate_correlations(SS19_F, SL041_F, "SS19_F", "SL041_F", "F", 68)

# Sixth Dyad
dyads_df <- calculate_correlations(SS19_F, SL045_F, "SS19_F", "SL045_F", "F", 69)

# Seventh Dyad
dyads_df <- calculate_correlations(SS19_F, SL053_F, "SS19_F", "SL053_F", "F", 70)

# Eighth Dyad
dyads_df <- calculate_correlations(SS19_F, SL056_F, "SS19_F", "SL056_F", "F", 71)

# Ninth Dyad
dyads_df <- calculate_correlations(SS19_F, SL057_F, "SS19_F", "SL057_F", "F", 72)

# Tenth Dyad
dyads_df <- calculate_correlations(SS19_F, SL058_F, "SS19_F", "SL058_F", "F", 73)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS19_F, SL059_F, "SS19_F", "SL059_F", "F", 74)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS19_F, SL061_F, "SS19_F", "SL061_F", "F", 75)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS19_F, SL065_F, "SS19_F", "SL065_F", "F", 76)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS19_F, SL074_F, "SS19_F", "SL074_F", "F", 77)

# Fifteenth Dyad
dyads_df <- calculate_correlations(SS19_F, SL075_F, "SS19_F", "SL075_F", "F", 78)

# Sixteenth Dyad
dyads_df <- calculate_correlations(SS19_F, SL089_F, "SS19_F", "SL089_F", "F", 79)

# Seventeenth Dyad
dyads_df <- calculate_correlations(SS19_F, SL091_F, "SS19_F", "SL091_F", "F", 80)

```

```{r, Speaker G}

# First Dyad
dyads_df <- calculate_correlations(SS23_G, SL032_G, "SS23_G", "SL032_G", "G", 81)

# Second Dyad
dyads_df <- calculate_correlations(SS23_G, SL036_G, "SS23_G", "SL036_G", "G", 82)

# Third Dyad
dyads_df <- calculate_correlations(SS23_G, SL038_G, "SS23_G", "SL038_G", "G", 83)

# Fourth Dyad
dyads_df <- calculate_correlations(SS23_G, SL040_G, "SS23_G", "SL040_G", "G", 84)

# Fifth Dyad
dyads_df <- calculate_correlations(SS23_G, SL048_G, "SS23_G", "SL048_G", "G", 85)

# Sixth Dyad
dyads_df <- calculate_correlations(SS23_G, SL052_G, "SS23_G", "SL052_G", "G", 86)

# Seventh Dyad
dyads_df <- calculate_correlations(SS23_G, SL053_G, "SS23_G", "SL053_G", "G", 87)

# Eighth Dyad
dyads_df <- calculate_correlations(SS23_G, SL055_G, "SS23_G", "SL055_G", "G", 88)

# Ninth Dyad
dyads_df <- calculate_correlations(SS23_G, SL056_G, "SS23_G", "SL056_G", "G", 89)

# Tenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL061_G, "SS23_G", "SL061_G", "G", 90)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS23_G, SL067_G, "SS23_G", "SL067_G", "G", 91)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS23_G, SL068_G, "SS23_G", "SL068_G", "G", 92)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL071_G, "SS23_G", "SL071_G", "G", 93)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL072_G, "SS23_G", "SL072_G", "G", 94)

# Fifteenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL075_G, "SS23_G", "SL075_G", "G", 95)

# Sixteenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL077_G, "SS23_G", "SL077_G", "G", 96)

# Seventeenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL078_G, "SS23_G", "SL078_G", "G", 97)

# Eighteenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL081_G, "SS23_G", "SL081_G", "G", 98)

# Nineteenth Dyad
dyads_df <- calculate_correlations(SS23_G, SL083_G, "SS23_G", "SL083_G", "G", 99)

# Twentieth Dyad
dyads_df <- calculate_correlations(SS23_G, SL092_G, "SS23_G", "SL092_G", "G", 100)

# Twenty-first Dyad
dyads_df <- calculate_correlations(SS23_G, SL094_G, "SS23_G", "SL094_G", "G", 101)

```

```{r, Speaker H}

# First Dyad
dyads_df <- calculate_correlations(SS24_H, SL033_H, "SS24_H", "SL033_H", "H", 102)

# Second Dyad
dyads_df <- calculate_correlations(SS24_H, SL034_H, "SS24_H", "SL034_H", "H", 103)

# Third Dyad
dyads_df <- calculate_correlations(SS24_H, SL035_H, "SS24_H", "SL035_H", "H", 104)

# Fourth Dyad
dyads_df <- calculate_correlations(SS24_H, SL037_H, "SS24_H", "SL037_H", "H", 105)

# Fifth Dyad
dyads_df <- calculate_correlations(SS24_H, SL038_H, "SS24_H", "SL038_H", "H", 106)

# Sixth Dyad
dyads_df <- calculate_correlations(SS24_H, SL039_H, "SS24_H", "SL039_H", "H", 107)

# Seventh Dyad
dyads_df <- calculate_correlations(SS24_H, SL042_H, "SS24_H", "SL042_H", "H", 108)

# Eighth Dyad
dyads_df <- calculate_correlations(SS24_H, SL053_H, "SS24_H", "SL053_H", "H", 109)

# Ninth Dyad
dyads_df <- calculate_correlations(SS24_H, SL055_H, "SS24_H", "SL055_H", "H", 110)

# Tenth Dyad
dyads_df <- calculate_correlations(SS24_H, SL056_H, "SS24_H", "SL056_H", "H", 111)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS24_H, SL065_H, "SS24_H", "SL065_H", "H", 112)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS24_H, SL067_H, "SS24_H", "SL067_H", "H", 113)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS24_H, SL073_H, "SS24_H", "SL073_H", "H", 114)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS24_H, SL076_H, "SS24_H", "SL076_H", "H", 115)

# Fifteenth Dyad
dyads_df <- calculate_correlations(SS24_H, SL077_H, "SS24_H", "SL077_H", "H", 116)

# Sixteenth Dyad
dyads_df <- calculate_correlations(SS24_H, SL083_H, "SS24_H", "SL083_H", "H", 117)

# Seventeenth Dyad
dyads_df <- calculate_correlations(SS24_H, SL089_H, "SS24_H", "SL089_H", "H", 118)

```

```{r, Speaker I}

# First Dyad
dyads_df <- calculate_correlations(SS30_I, SL042_I, "SS30_I", "SL042_I", "I", 119)

# Second Dyad
dyads_df <- calculate_correlations(SS30_I, SL048_I, "SS30_I", "SL048_I", "I", 120)

# Third Dyad
dyads_df <- calculate_correlations(SS30_I, SL063_I, "SS30_I", "SL063_I", "I", 121)

# Fourth Dyad
dyads_df <- calculate_correlations(SS30_I, SL070_I, "SS30_I", "SL070_I", "I", 122)

# Fifth Dyad
dyads_df <- calculate_correlations(SS30_I, SL071_I, "SS30_I", "SL071_I", "I", 123)

# Sixth Dyad
dyads_df <- calculate_correlations(SS30_I, SL072_I, "SS30_I", "SL072_I", "I", 124)

# Seventh Dyad
dyads_df <- calculate_correlations(SS30_I, SL073_I, "SS30_I", "SL073_I", "I", 125)

# Eighth Dyad
dyads_df <- calculate_correlations(SS30_I, SL079_I, "SS30_I", "SL079_I", "I", 126)

# Ninth Dyad
dyads_df <- calculate_correlations(SS30_I, SL084_I, "SS30_I", "SL084_I", "I", 127)

# Tenth Dyad
dyads_df <- calculate_correlations(SS30_I, SL085_I, "SS30_I", "SL085_I", "I", 128)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS30_I, SL088_I, "SS30_I", "SL088_I", "I", 129)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS30_I, SL094_I, "SS30_I", "SL094_I", "I", 130)

```

```{r, Speaker J}

# First Dyad
dyads_df <- calculate_correlations(SS31_J, SL032_J, "SS31_J", "SL032_J", "J", 131)

# Second Dyad
dyads_df <- calculate_correlations(SS31_J, SL035_J, "SS31_J", "SL035_J", "J", 132)

# Third Dyad
dyads_df <- calculate_correlations(SS31_J, SL044_J, "SS31_J", "SL044_J", "J", 133)

# Fourth Dyad
dyads_df <- calculate_correlations(SS31_J, SL051_J, "SS31_J", "SL051_J", "J", 134)

# Fifth Dyad
dyads_df <- calculate_correlations(SS31_J, SL052_J, "SS31_J", "SL052_J", "J", 135)

# Sixth Dyad
dyads_df <- calculate_correlations(SS31_J, SL054_J, "SS31_J", "SL054_J", "J", 136)

# Seventh Dyad
dyads_df <- calculate_correlations(SS31_J, SL061_J, "SS31_J", "SL061_J", "J", 137)

# Eighth Dyad
dyads_df <- calculate_correlations(SS31_J, SL071_J, "SS31_J", "SL071_J", "J", 138)

# Ninth Dyad
dyads_df <- calculate_correlations(SS31_J, SL073_J, "SS31_J", "SL073_J", "J", 139)

# Tenth Dyad
dyads_df <- calculate_correlations(SS31_J, SL074_J, "SS31_J", "SL074_J", "J", 140)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS31_J, SL076_J, "SS31_J", "SL076_J", "J", 141)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS31_J, SL077_J, "SS31_J", "SL077_J", "J", 142)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS31_J, SL078_J, "SS31_J", "SL078_J", "J", 143)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS31_J, SL081_J, "SS31_J", "SL081_J", "J", 144)

```

```{r, Speaker K}

# First Dyad
dyads_df <- calculate_correlations(SS33_K, SL034_K, "SS33_K", "SL034_K", "K", 145)

# Second Dyad
dyads_df <- calculate_correlations(SS33_K, SL037_K, "SS33_K", "SL037_K", "K", 146)

# Third Dyad
dyads_df <- calculate_correlations(SS33_K, SL038_K, "SS33_K", "SL038_K", "K", 147)

# Fourth Dyad
dyads_df <- calculate_correlations(SS33_K, SL040_K, "SS33_K", "SL040_K", "K", 148)

# Fifth Dyad
dyads_df <- calculate_correlations(SS33_K, SL041_K, "SS33_K", "SL041_K", "K", 149)

# Sixth Dyad
dyads_df <- calculate_correlations(SS33_K, SL045_K, "SS33_K", "SL045_K", "K", 150)

# Seventh Dyad
dyads_df <- calculate_correlations(SS33_K, SL046_K, "SS33_K", "SL046_K", "K", 151)

# Eighth Dyad
dyads_df <- calculate_correlations(SS33_K, SL047_K, "SS33_K", "SL047_K", "K", 152)

# Ninth Dyad
dyads_df <- calculate_correlations(SS33_K, SL059_K, "SS33_K", "SL059_K", "K", 153)

# Tenth Dyad
dyads_df <- calculate_correlations(SS33_K, SL064_K, "SS33_K", "SL064_K", "K", 154)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS33_K, SL069_K, "SS33_K", "SL069_K", "K", 155)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS33_K, SL094_K, "SS33_K", "SL094_K", "K", 156)

```

```{r, Speaker L}

# First Dyad
dyads_df <- calculate_correlations(SS34_L, SL032_L, "SS34_L", "SL032_L", "L", 157)

# Second Dyad
dyads_df <- calculate_correlations(SS34_L, SL035_L, "SS34_L", "SL035_L", "L", 158)

# Third Dyad
dyads_df <- calculate_correlations(SS34_L, SL039_L, "SS34_L", "SL039_L", "L", 159)

# Fourth Dyad
dyads_df <- calculate_correlations(SS34_L, SL042_L, "SS34_L", "SL042_L", "L", 160)

# Fifth Dyad
dyads_df <- calculate_correlations(SS34_L, SL044_L, "SS34_L", "SL044_L", "L", 161)

# Sixth Dyad
dyads_df <- calculate_correlations(SS34_L, SL046_L, "SS34_L", "SL046_L", "L", 162)

# Seventh Dyad
dyads_df <- calculate_correlations(SS34_L, SL047_L, "SS34_L", "SL047_L", "L", 163)

# Eighth Dyad
dyads_df <- calculate_correlations(SS34_L, SL048_L, "SS34_L", "SL048_L", "L", 164)

# Ninth Dyad
dyads_df <- calculate_correlations(SS34_L, SL054_L, "SS34_L", "SL054_L", "L", 165)

# Tenth Dyad
dyads_df <- calculate_correlations(SS34_L, SL057_L, "SS34_L", "SL057_L", "L", 166)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS34_L, SL059_L, "SS34_L", "SL059_L", "L", 167)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS34_L, SL065_L, "SS34_L", "SL065_L", "L", 168)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS34_L, SL068_L, "SS34_L", "SL068_L", "L", 169)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS34_L, SL072_L, "SS34_L", "SL072_L", "L", 170)

# Fifteenth Dyad
dyads_df <- calculate_correlations(SS34_L, SL073_L, "SS34_L", "SL073_L", "L", 171)

# Sixteenth Dyad
dyads_df <- calculate_correlations(SS34_L, SL089_L, "SS34_L", "SL089_L", "L", 172)

```

```{r, Speaker M}

# First Dyad
dyads_df <- calculate_correlations(SS41_M, SL036_M, "SS41_M", "SL036_M", "M", 173)

# Second Dyad
dyads_df <- calculate_correlations(SS41_M, SL038_M, "SS41_M", "SL038_M", "M", 174)

# Third Dyad
dyads_df <- calculate_correlations(SS41_M, SL047_M, "SS41_M", "SL047_M", "M", 175)

# Fourth Dyad
dyads_df <- calculate_correlations(SS41_M, SL050_M, "SS41_M", "SL050_M", "M", 176)

# Fifth Dyad
dyads_df <- calculate_correlations(SS41_M, SL052_M, "SS41_M", "SL052_M", "M", 177)

# Sixth Dyad
dyads_df <- calculate_correlations(SS41_M, SL069_M, "SS41_M", "SL069_M", "M", 178)

# Seventh Dyad
dyads_df <- calculate_correlations(SS41_M, SL076_M, "SS41_M", "SL076_M", "M", 179)

# Eighth Dyad
dyads_df <- calculate_correlations(SS41_M, SL077_M, "SS41_M", "SL077_M", "M", 180)

# Ninth Dyad
dyads_df <- calculate_correlations(SS41_M, SL079_M, "SS41_M", "SL079_M", "M", 181)

# Tenth Dyad
dyads_df <- calculate_correlations(SS41_M, SL086_M, "SS41_M", "SL086_M", "M", 182)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS41_M, SL091_M, "SS41_M", "SL091_M", "M", 183)

```

```{r, Speaker N}

# First Dyad
dyads_df <- calculate_correlations(SS42_N, SL035_N, "SS42_N", "SL035_N", "N", 184)

# Second Dyad
dyads_df <- calculate_correlations(SS42_N, SL036_N, "SS42_N", "SL036_N", "N", 185)

# Third Dyad
dyads_df <- calculate_correlations(SS42_N, SL041_N, "SS42_N", "SL041_N", "N", 186)

# Fourth Dyad
dyads_df <- calculate_correlations(SS42_N, SL042_N, "SS42_N", "SL042_N", "N", 187)

# Fifth Dyad
dyads_df <- calculate_correlations(SS42_N, SL044_N, "SS42_N", "SL044_N", "N", 188)

# Sixth Dyad
dyads_df <- calculate_correlations(SS42_N, SL050_N, "SS42_N", "SL050_N", "N", 189)

# Seventh Dyad
dyads_df <- calculate_correlations(SS42_N, SL057_N, "SS42_N", "SL057_N", "N", 190)

# Eighth Dyad
dyads_df <- calculate_correlations(SS42_N, SL058_N, "SS42_N", "SL058_N", "N", 191)

# Ninth Dyad
dyads_df <- calculate_correlations(SS42_N, SL063_N, "SS42_N", "SL063_N", "N", 192)

# Tenth Dyad
dyads_df <- calculate_correlations(SS42_N, SL064_N, "SS42_N", "SL064_N", "N", 193)

# Eleventh Dyad
dyads_df <- calculate_correlations(SS42_N, SL067_N, "SS42_N", "SL067_N", "N", 194)

# Twelfth Dyad
dyads_df <- calculate_correlations(SS42_N, SL068_N, "SS42_N", "SL068_N", "N", 195)

# Thirteenth Dyad
dyads_df <- calculate_correlations(SS42_N, SL069_N, "SS42_N", "SL069_N", "N", 196)

# Fourteenth Dyad
dyads_df <- calculate_correlations(SS42_N, SL094_N, "SS42_N", "SL094_N", "N", 197)

```

```{r, data cleaning for shared experience, alexithymia scores, and ADHD scores}

#Renaming data frame and filtering for people who completed the study, as well as specific variables of interest
SGG_Storytelling_Study_Listeners_April_1_2025_14_12 <- read_csv("~/Library/CloudStorage/Box-Box/MICLab/projects/Storytelling_Study/data/listener_behavioral/SGG Storytelling Study - Listeners_April 1, 2025_14.12.csv")

shared_exp <- SGG_Storytelling_Study_Listeners_April_1_2025_14_12 %>%
  filter(Finished == TRUE) %>%
  select(ID, vids, simA_1, simexpB_1, simexpC_1, simexpD_1, simexpE_1, simexpF_1, simexpG_1, 
         simexpH_1, simexpI_1, simexpJ_1, simexpK_1, simexpL_1, simexpM_1, simexpN_1, 
         TAS_1, TAS_2, TAS_3, TAS_4, TAS_5, TAS_6, TAS_7, TAS_8, TAS_9, TAS_10, TAS_11, 
         TAS_12, TAS_13, TAS_14, TAS_15, TAS_16, TAS_17, TAS_18, TAS_19, TAS_20, ADHD_1, ADHD_2, ADHD_3,
         ADHD_4, ADHD_5, ADHD_6, ADHD_7, ADHD_8, ADHD_9, ADHD_10, ADHD_11, ADHD_12, ADHD_13, ADHD_14, ADHD_15,
         ADHD_16, ADHD_17, ADHD_18, age, gender, race, SES)

#Recoding all values to numeric forms for shared experience variable 
recode <-  c("Strongly disagree" = 1, "Moderately disagree" = 2, "Slightly disagree" = 3, "Neither agree nor disagree" = 4, "Slightly agree" = 5, "Moderately agree" = 6, "Strongly agree" = 7) 

# List of variables for recoding shared experience 
shared_exp_vars <- c("simA_1", "simexpB_1", "simexpC_1", "simexpD_1", "simexpE_1", 
                    "simexpF_1", "simexpG_1", "simexpH_1", "simexpI_1", "simexpJ_1", 
                    "simexpK_1", "simexpL_1", "simexpM_1", "simexpN_1")

#Rewriting shared experience variable to  the recoded version of this variable
for (var in shared_exp_vars) {
  shared_exp[[var]] <- recode[shared_exp[[var]]]
}

#Recoding values to numeric forms for alexithymia variable 
recode2 <-  c("Strongly disagree" = 1, "Disagree moderately" = 2, "Disagree a little" = 3, "Agree a little" = 4, "Agree moderately" = 5, "Strongly agree" = 6) 

#List of variables for recoding alexithymia
alexi_vars <- c("TAS_1", "TAS_2", "TAS_3", "TAS_6", "TAS_7", "TAS_8", "TAS_9", "TAS_11", 
                "TAS_12", "TAS_13", "TAS_14", "TAS_15", "TAS_16", "TAS_17", "TAS_20")

#Recoding values to numeric forms for alexithymia items that are negatively keyed 
recode3 <-  c("Strongly disagree" = 6, "Disagree moderately" = 5, "Disagree a little" = 4, "Agree a little" = 3, "Agree moderately" = 2, "Strongly agree" = 1)

#List of variables for recoding alexithymia items that are negatively keyed
alexi_vars2 <- c("TAS_4", "TAS_5", "TAS_10", "TAS_18", "TAS_19")

#Rewriting alexithymia variable to  the recoded version of this variable
for (var in alexi_vars) {
  shared_exp[[var]] <- recode2[shared_exp[[var]]]
}

for (var in alexi_vars2) {
  shared_exp[[var]] <- recode3[shared_exp[[var]]]
}

#Calculating a Composite TAS Score
shared_exp$TASscore <- rowSums(shared_exp[,c("TAS_1", "TAS_2", "TAS_3", "TAS_6", "TAS_7", "TAS_8", "TAS_9", "TAS_11", "TAS_12", "TAS_13", "TAS_14", "TAS_15", "TAS_16", "TAS_17", "TAS_20", "TAS_4", "TAS_5", "TAS_10", "TAS_18", "TAS_19")], na.rm = TRUE)
shared_exp$TASscore[shared_exp$TASscore == 0] <- NA

#Recoding all values to numeric forms for ADHD variable 
recode4 <-  c("Never" = 0, "Rarely" = 1, "Sometimes" = 2, "Often" = 3, "Very often" = 4) 

# List of variables for recoding shared experience 
ADHD_vars <- c("ADHD_1", "ADHD_2", "ADHD_3", "ADHD_4", "ADHD_5", "ADHD_6", "ADHD_7", 
               "ADHD_8", "ADHD_9", "ADHD_10", "ADHD_11", "ADHD_12", "ADHD_13", 
               "ADHD_14", "ADHD_15", "ADHD_16", "ADHD_17", "ADHD_18")

#Rewriting ADHD variable to  the recoded version of this variable
for (var in ADHD_vars) {
  shared_exp[[var]] <- recode4[shared_exp[[var]]]
}

#Calculating a Composite ADHD Score
shared_exp$ADHDscore <- rowSums(shared_exp[,c("ADHD_1", "ADHD_2", "ADHD_3", "ADHD_4", "ADHD_5", "ADHD_6", "ADHD_7", "ADHD_8", "ADHD_9", "ADHD_10", "ADHD_11", "ADHD_12", "ADHD_13", "ADHD_14", "ADHD_15", "ADHD_16", "ADHD_17", "ADHD_18")], na.rm = TRUE)
shared_exp$ADHDscore[shared_exp$ADHDscore == 0] <- NA

#Calculating a PART A ADHD Score
shared_exp$ADHDscoreA <- rowSums(shared_exp[,c("ADHD_1", "ADHD_2", "ADHD_3", "ADHD_4", "ADHD_5", "ADHD_6")], na.rm = TRUE)
shared_exp$ADHDscoreA[shared_exp$ADHDscoreA == 0] <- NA

#Calculating a PART B ADHD Score
shared_exp$ADHDscoreB <- rowSums(shared_exp[,c("ADHD_7", "ADHD_8", "ADHD_9", "ADHD_10", "ADHD_11", "ADHD_12", "ADHD_13", "ADHD_14", "ADHD_15", "ADHD_16", "ADHD_17", "ADHD_18")], na.rm = TRUE)
shared_exp$ADHDscoreB[shared_exp$ADHDscoreB == 0] <- NA

# Extract the numeric part from dyads_df$listener_id and shared_exp$ID to put information into original df
dyads_df$listener_id_num <- gsub("[^0-9]", "", dyads_df$listener_id)
shared_exp$ID_num <- gsub("[^0-9]", "", shared_exp$ID)

# Perform the left join using the numeric IDs and include additional variables (age, race, gender, SES)
dyads_df <- dyads_df %>%
  left_join(shared_exp %>%
              select(ID_num, TASscore, ADHDscore, age, race, gender, SES), 
            by = c("listener_id_num" = "ID_num"))

```

```{r, inputting shared experience scores into original data frame since these are repeated}

# Handling shared experience scores for each letter
dyads_df$listener_letter <- gsub(".*_", "", dyads_df$listener_id)  # Extract the letter part

# Renaming variables for consistency
names(shared_exp)[names(shared_exp) == "simA_1"] <- "simexpA_1"

# Loop over letters and assign shared experience scores
for (letter in LETTERS[1:14]) {
  simexp_var <- paste0("simexp", letter, "_1")
  
  if (!simexp_var %in% colnames(shared_exp)) {
    next
  }
  
  temp_df <- shared_exp %>%
    select(ID_num, all_of(simexp_var))
  
  dyads_df <- dyads_df %>%
    left_join(temp_df, by = c("listener_id_num" = "ID_num"))
  
  dyads_df$shared_exp[dyads_df$listener_letter == letter] <- dyads_df[[simexp_var]][dyads_df$listener_letter == letter]
}

```

```{r, Multilevel, Mixed Effects Model}

# Convert shared_exp to numeric
dyads_df$shared_exp <- as.numeric(dyads_df$shared_exp)

# Fit base interaction model for each channel
base_model_list <- list()

for (ch in 1:100) {
  formula <- as.formula(paste0("ch", ch, " ~ shared_exp * ADHDscore + TASscore + (1 | speaker_id) + (1 | listener_id_num)"))
  base_model_list[[paste0("ch", ch)]] <- lmer(formula, data = dyads_df)
  
  print(paste0("Summary of base model for channel ", ch))
  print(summary(base_model_list[[paste0("ch", ch)]]))
}

```

```{r, rank order mixed effects model for original model}

# Rank predictors and outcome variables
dyads_ranked_interaction <- dyads_df %>%
  mutate(
    shared_exp_rank = rank(shared_exp),
    ADHDscore_rank = rank(ADHDscore),
    TASscore_rank = rank(TASscore)
  ) %>%
  mutate(across(all_of(paste0("ch", 1:100)), ~rank(.)))

# Fit rank-transformed interaction model
rank_model_results <- data.frame()

for (ch in 1:100) {
  formula <- as.formula(paste0("ch", ch, " ~ shared_exp_rank * ADHDscore_rank + TASscore_rank + 
                               (1 | speaker_id) + (1 | listener_id_num)"))
  
  model <- lmer(formula, data = dyads_ranked_interaction)
  
  tidy_summary <- broom.mixed::tidy(model, effects = "fixed") %>%
    mutate(channel = paste0("ch", ch))
  
  rank_model_results <- bind_rows(rank_model_results, tidy_summary)
}

# FDR correction
rank_model_results <- rank_model_results %>%
  group_by(term) %>%
  mutate(p_adj_fdr = p.adjust(p.value, method = "fdr")) %>%
  ungroup()

sig_rank_results <- filter(rank_model_results, p_adj_fdr < 0.05)
head(sig_rank_results)

```

```{r, correcting for multiple comparisons for original model}

# Extract p-values for shared_exp:ADHDscore interaction
p_values_interaction <- sapply(base_model_list, function(model) {
  summary(model)$coefficients["shared_exp:ADHDscore", "Pr(>|t|)"]
})

p_adj_interaction <- p.adjust(p_values_interaction, method = "fdr")
print(p_adj_interaction)

```

```{r, checking assumptions}

library(performance)
library(car)

icc_values <- list()
shapiro_results <- list()

for (ch in 1:100) {
  model <- base_model_list[[paste0("ch", ch)]]
  
  # ICC
  icc_values[[paste0("ch", ch)]] <- performance::icc(model)
  print(paste0("ICC for channel ", ch, ":"))
  print(icc_values[[paste0("ch", ch)]])
  
  # Homoscedasticity
  plot(fitted(model), resid(model), main = paste("Residuals vs Fitted (Ch", ch, ")"))
  abline(h = 0, col = "red")
  
  # Normality
  qqnorm(resid(model), main = paste("QQ Plot (Ch", ch, ")"))
  qqline(resid(model))
  
  # Shapiro-Wilk test
  shapiro_results[[paste0("ch", ch)]] <- shapiro.test(residuals(model))
  print(paste0("Shapiro-Wilk for Channel ", ch, ":"))
  print(shapiro_results[[paste0("ch", ch)]])
}

# VIF check (on fixed formula)
vif_model <- lmer(shared_exp ~ ADHDscore + TASscore + (1 | speaker_id) + (1 | listener_id_num), data = dyads_df)
print(vif(vif_model))

```

```{r, model 2 testing for exploratory analyses shared_exp score}

shared_exp_model_list <- list()
p_values_shared_exp <- c()

for (ch in 1:100) {
  formula <- as.formula(paste0("ch", ch, " ~ shared_exp + (1 | speaker_id) + (1 | listener_id_num)"))
  model <- lmer(formula, data = dyads_df)
  shared_exp_model_list[[paste0("ch", ch)]] <- model
  
  p_val <- summary(model)$coefficients["shared_exp", "Pr(>|t|)"]
  p_values_shared_exp <- c(p_values_shared_exp, p_val)
}

p_adj_shared_exp <- p.adjust(p_values_shared_exp, method = "fdr")
print(p_adj_shared_exp)

```

```{r, rank order mixed effects model for shared experience only model}

# Rank predictors and outcome variables
dyads_ranked_shared_exp <- dyads_df %>%
  mutate(shared_exp_rank = rank(shared_exp)) %>%
  mutate(across(all_of(paste0("ch", 1:100)), ~rank(.)))

shared_exp_rank_results <- data.frame()

for (ch in 1:100) {
  formula <- as.formula(paste0("ch", ch, " ~ shared_exp_rank + (1 | speaker_id) + (1 | listener_id_num)"))
  model <- lmer(formula, data = dyads_ranked_shared_exp)
  
  tidy_summary <- broom.mixed::tidy(model, effects = "fixed") %>%
    mutate(channel = paste0("ch", ch))
  
  shared_exp_rank_results <- bind_rows(shared_exp_rank_results, tidy_summary)
}

shared_exp_rank_results <- shared_exp_rank_results %>%
  group_by(term) %>%
  mutate(p_adj_fdr = p.adjust(p.value, method = "fdr")) %>%
  ungroup()

sig_shared_exp_rank <- filter(shared_exp_rank_results, p_adj_fdr < 0.05)
head(sig_shared_exp_rank)

```

```{r, model 3 testing for exploratory analyses ADHDscore}

adhd_model_list <- list()
p_values_adhd <- c()

for (ch in 1:100) {
  formula <- as.formula(paste0("ch", ch, " ~ ADHDscore + (1 | speaker_id) + (1 | listener_id_num)"))
  model <- lmer(formula, data = dyads_df)
  adhd_model_list[[paste0("ch", ch)]] <- model
  
  p_val <- summary(model)$coefficients["ADHDscore", "Pr(>|t|)"]
  p_values_adhd <- c(p_values_adhd, p_val)
}

p_adj_adhd <- p.adjust(p_values_adhd, method = "fdr")
print(p_adj_adhd)

```

```{r, rank order mixed effects model for ADHD only model}

# Rank predictors and outcome variables
dyads_ranked_adhd <- dyads_df %>%
  mutate(ADHDscore_rank = rank(ADHDscore)) %>%
  mutate(across(all_of(paste0("ch", 1:100)), ~rank(.)))

# Initialize list and results dataframe
adhd_rank_model_list <- list()
adhd_rank_results <- data.frame()

# Fit models per channel
for (ch in 1:100) {
  formula_adhd_rank <- as.formula(paste0("ch", ch, " ~ ADHDscore_rank + (1 | speaker_id) + (1 | listener_id_num)"))
  
  model <- lmer(formula_adhd_rank, data = dyads_ranked_adhd)
  
  # Save model
  adhd_rank_model_list[[paste0("ch", ch)]] <- model
  
  # Extract and save results
  model_summary <- broom.mixed::tidy(model, effects = "fixed") %>%
    mutate(channel = paste0("ch", ch))
  
  adhd_rank_results <- bind_rows(adhd_rank_results, model_summary)
}

# Apply FDR correction
adhd_rank_results <- adhd_rank_results %>%
  group_by(term) %>%
  mutate(p_adj_fdr = p.adjust(p.value, method = "fdr")) %>%
  ungroup()

# Filter for significant ADHDscore_rank effects
sig_adhd_rank_results <- adhd_rank_results %>%
  filter(term == "ADHDscore_rank", p_adj_fdr < 0.05)

# View results
head(sig_adhd_rank_results)

```

```{r, model 4 testing for exploratory analyses TASscore}

# Initialize model list and p-value vector
tas_model_list <- list()
tas_p_values <- c()

# Fit models
for (ch in 1:100) {
  formula_tas <- as.formula(paste0("ch", ch, " ~ TASscore + (1 | speaker_id) + (1 | listener_id_num)"))
  
  model <- lmer(formula_tas, data = dyads_df)
  
  # Save model
  tas_model_list[[paste0("ch", ch)]] <- model
  
  # Print summary (optional)
  print(paste0("Summary of model for channel ", ch))
  print(summary(model))
  
  # Extract p-value
  p_val <- summary(model)$coefficients["TASscore", "Pr(>|t|)"]
  tas_p_values <- c(tas_p_values, p_val)
}

# FDR correction
tas_p_values_fdr <- p.adjust(tas_p_values, method = "fdr")

# View results
print(tas_p_values_fdr)

```

```{r, rank order mixed effects model for TAS only model}

# Rank predictors and outcome variables
dyads_ranked_tas <- dyads_df %>%
  mutate(TASscore_rank = rank(TASscore)) %>%
  mutate(across(all_of(paste0("ch", 1:100)), ~rank(.)))

# Initialize list and results dataframe
tas_rank_model_list <- list()
tas_rank_results <- data.frame()

# Fit models per channel
for (ch in 1:100) {
  formula_tas_rank <- as.formula(paste0("ch", ch, " ~ TASscore_rank + (1 | speaker_id) + (1 | listener_id_num)"))
  
  model <- lmer(formula_tas_rank, data = dyads_ranked_tas)
  
  # Save model
  tas_rank_model_list[[paste0("ch", ch)]] <- model
  
  # Extract and save results
  model_summary <- broom.mixed::tidy(model, effects = "fixed") %>%
    mutate(channel = paste0("ch", ch))
  
  tas_rank_results <- bind_rows(tas_rank_results, model_summary)
}

# Apply FDR correction
tas_rank_results <- tas_rank_results %>%
  group_by(term) %>%
  mutate(p_adj_fdr = p.adjust(p.value, method = "fdr")) %>%
  ungroup()

# Filter for significant TASscore_rank effects
sig_tas_rank_results <- tas_rank_results %>%
  filter(term == "TASscore_rank", p_adj_fdr < 0.05)

# View results
head(sig_tas_rank_results)

```

```{r, demographics cleaning and table}

# Load necessary packages
library(dplyr)
library(flextable)

# Compute descriptive statistics and round values
desc_stats <- data.frame(
  Variable = c("Age", "ADHD Score", "ADHD Score A", "ADHD Score B", "TAS Score", "Shared Experience Score"),
  M = c(round(mean(shared_exp$age, na.rm = TRUE), 2),
        round(mean(shared_exp$ADHDscore, na.rm = TRUE), 2),
        round(mean(shared_exp$ADHDscoreA, na.rm = TRUE), 2),
        round(mean(shared_exp$ADHDscoreB, na.rm = TRUE), 2),
        round(mean(dyads_df$TASscore, na.rm = TRUE), 2),
        round(mean(dyads_df$shared_exp, na.rm = TRUE), 2)),
  SD = c(round(sd(shared_exp$age, na.rm = TRUE), 2),
         round(sd(shared_exp$ADHDscore, na.rm = TRUE), 2),
         round(sd(shared_exp$ADHDscoreA, na.rm = TRUE), 2),
         round(sd(shared_exp$ADHDscoreB, na.rm = TRUE), 2),
         round(sd(dyads_df$TASscore, na.rm = TRUE), 2),
         round(sd(dyads_df$shared_exp, na.rm = TRUE), 2))
)

# Create APA-formatted table
apa_table <- flextable(desc_stats) %>%
  set_header_labels(Variable = "Variable", M = "M", SD = "SD") %>%  # Rename columns to "M" and "SD"
  fontsize(size = 12) %>%                                            # Set font size to 12
  font(fontname = "Times New Roman", part = "all") %>%               # Use Times New Roman
  align(align = "center", part = "all") %>%                          # Center text
  italic(j = 2:3, part = "header") %>%                               # Italicize "M" and "SD" in the header
  color(color = "black", part = "all") %>%                           # Ensure black font color
  width(j = 1, width = 2.5) %>%                                      # Adjust column widths
  width(j = 2:3, width = 1)                                          # Adjust "M" and "SD" column widths

# Print table
apa_table

```

```{r, APA table for estimates}

# Read the CSV file with MNI coordinates
data <- read_csv("~/Downloads/mni_coordinates_100_channels.csv")

# Round the coordinates for cleaner display (optional)
data_clean <- data %>%
  mutate(across(c(X, Y, Z), ~ round(.x, 2))) %>%
  rename(
    `Channel` = Channel,
    `X` = X,
    `Y` = Y,
    `Z` = Z
  )

# Initialize vectors to store t-values, p-values, and FDR-corrected p-values
t_values <- c()
p_values <- c()

# Loop through each model in the model list to extract t-values and p-values
for (model_name in names(base_model_list)) {
  # Extract the summary of the model
  summary_model <- summary(base_model_list[[model_name]])
  
  # Extract the t-value and p-value for the interaction term 'shared_exp:ADHDscore'
  t_value <- summary_model$coefficients["shared_exp:ADHDscore", "t value"]
  p_value <- summary_model$coefficients["shared_exp:ADHDscore", "Pr(>|t|)"]
  
  # Save the t-value and p-value in the respective vectors
  t_values <- c(t_values, t_value)
  p_values <- c(p_values, p_value)
}

# Apply FDR correction to the p-values
p_values_fdr_corrected <- p.adjust(p_values, method = "fdr")

# Create a data frame to store the results
results_df <- data.frame(
  Channel = 1:100,
  t_value = round(t_values, 2),
  p_value = round(p_values, 4),
  q_value = round(p_values_fdr_corrected, 4)
)

# Merge the MNI coordinates with the results dataframe, remove Channel from results_df to avoid duplication
final_df <- cbind(results_df, data_clean[, c("X", "Y", "Z")])

# Create an APA-formatted table using flextable
apa_table2 <- flextable(final_df) %>%
  set_header_labels(
    Channel = "Channel",
    t_value = "t",
    p_value = "p",
    q_value = "q (FDR corrected)",
    X = "X (MNI)",
    Y = "Y (MNI)",
    Z = "Z (MNI)"
  ) %>%
  fontsize(size = 12) %>%  # Set font size to 12
  font(fontname = "Times New Roman", part = "all") %>%  # Use Times New Roman
  align(align = "center", part = "all") %>%  # Center text
  italic(j = 1:7, part = "header") %>%  # Italicize all headers
  color(color = "black", part = "all") %>%  # Ensure black font color
  width(j = 1, width = 2.5) %>%  # Adjust column width for "Channel"
  width(j = 2:4, width = 1) %>%  # Adjust "t", "p", and "q" column widths
  width(j = 5:7, width = 2)  # Adjust column width for MNI coordinates

# Print the table
print(apa_table2)

```

